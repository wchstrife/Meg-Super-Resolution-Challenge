{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超分辨率训练和测试范例\n",
    "\n",
    "这里提供一个超分辨率模型的训练和测试范例。\n",
    "\n",
    "首先，我们假定您的训练数据和测试数据存在下面的位置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RAW_DATA = \"./dataset/game1/train_png/\"\n",
    "TEST_RAW_DATA = \"./dataset/game1/test.tar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理训练数据\n",
    "\n",
    "我们已将数据集解压在./dataset/game1/train_png/，因此您无需专门解压缩数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假定您要将训练数据存储在下面位置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_STORAGE = \"./workspace/train_patches\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "则用下面的代码处理您的训练数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [05:07<00:00,  3.42s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import tarfile\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "#TRAIN_RAW_DATA='./train_png/'\n",
    "#TRAIN_DATA_STORAGE='./train_patches/'\n",
    "\n",
    "random.seed(100)\n",
    "os.makedirs(TRAIN_DATA_STORAGE, exist_ok=True)\n",
    "\n",
    "tasks = sorted([os.path.join(TRAIN_RAW_DATA,i) for i in os.listdir(TRAIN_RAW_DATA) if 'down4x' in i])\n",
    "\n",
    "count = 0\n",
    "for task in tqdm(tasks):\n",
    "    task_origin = task.replace('_down4x.mp4','')\n",
    "    frames_origin = sorted([os.path.join(task_origin,i) for i in os.listdir(task_origin)])\n",
    "    frames_down4x = sorted([os.path.join(task,i) for i in os.listdir(task)])\n",
    "\n",
    "    for k, (frame_down4x,\n",
    "            frame_origin) in enumerate(zip(frames_down4x, frames_origin)):\n",
    "        if random.random() < 0.1:\n",
    "            img_origin = cv2.imread(frame_origin)\n",
    "            if img_origin.shape[0] < 256 or img_origin.shape[1] < 256:\n",
    "                continue\n",
    "                \n",
    "            img_down4x = cv2.imread(frame_down4x)\n",
    "            img_down4x = cv2.resize(\n",
    "                img_down4x, (img_origin.shape[1], img_origin.shape[0]))\n",
    "\n",
    "            x0 = random.randrange(img_origin.shape[0] - 256 + 1)\n",
    "            y0 = random.randrange(img_origin.shape[1] - 256 + 1)\n",
    "\n",
    "            img_show = np.float32(\n",
    "                np.stack((img_down4x[x0:x0 + 256, y0:y0 + 256].transpose((2, 0, 1)),\n",
    "                          img_origin[x0:x0 + 256, y0:y0 + 256].transpose((2, 0, 1))))) / 256\n",
    "            np.save(os.path.join(TRAIN_DATA_STORAGE, '%04d.npy' % count), img_show)\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "作为示例，我们构建一个简单的网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import megengine as mge\n",
    "import megengine.module as M\n",
    "import megengine.functional as F\n",
    "\n",
    "def addLeakyRelu(x):\n",
    "    return M.Sequential(x, M.LeakyReLU(0.2))\n",
    "\n",
    "def addPadding(x):\n",
    "    shape = x.shape\n",
    "    padding_shape = [(k + 1) // 2 * 2 for k in shape]\n",
    "    res = mge.zeros(padding_shape, dtype=x.dtype)\n",
    "    res = res.set_subtensor(x)[:shape[0], :shape[1], :shape[2], :shape[3]]\n",
    "    return res\n",
    "\n",
    "class SimpleUNet(M.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv0 = addLeakyRelu(M.Conv2d(3, 32, 4, padding=1, stride=2))\n",
    "        self.conv1 = addLeakyRelu(M.Conv2d(32, 64, 4, padding=1, stride=2))\n",
    "        self.conv2 = addLeakyRelu(M.Conv2d(64, 128, 4, padding=1, stride=2))\n",
    "        self.conv3 = addLeakyRelu(M.Conv2d(128, 256, 4, padding=1, stride=2))\n",
    "        self.conv4 = addLeakyRelu(M.Conv2d(256, 512, 4, padding=1, stride=2))\n",
    "        self.conv5 = addLeakyRelu(M.Conv2d(512, 1024, 4, padding=1, stride=2))\n",
    "        self.deconv5 = addLeakyRelu(M.ConvTranspose2d(1024, 512, 4, stride=2, padding=1))\n",
    "        self.deconv4 = addLeakyRelu(M.ConvTranspose2d(1024, 256, 4, stride=2, padding=1))\n",
    "        self.deconv3 = addLeakyRelu(M.ConvTranspose2d(512, 128, 4, stride=2, padding=1))\n",
    "        self.deconv2 = addLeakyRelu(M.ConvTranspose2d(256, 64, 4, stride=2, padding=1))\n",
    "        self.deconv1 = addLeakyRelu(M.ConvTranspose2d(128, 32, 4, stride=2, padding=1))\n",
    "        self.deconv0 = addLeakyRelu(M.ConvTranspose2d(64, 3, 4, stride=2, padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv0 = addPadding(self.conv0(x))\n",
    "        conv1 = addPadding(self.conv1(conv0))\n",
    "        conv2 = addPadding(self.conv2(conv1))\n",
    "        conv3 = addPadding(self.conv3(conv2))\n",
    "        conv4 = addPadding(self.conv4(conv3))\n",
    "        conv5 = self.conv5(conv4)\n",
    "\n",
    "        conv5 = self.deconv5(conv5)[:, :, :conv4.shape[2], :conv4.shape[3]]  #  1/32   512\n",
    "        conv4 = self.deconv4(F.concat([conv5, conv4], 1))[:, :, :conv3.shape[2], :conv3.shape[3]]  #  1/16   256\n",
    "        conv3 = self.deconv3(F.concat([conv4, conv3], 1))[:, :, :conv2.shape[2], :conv2.shape[3]]  #  1/8   128\n",
    "        conv2 = self.deconv2(F.concat([conv3, conv2], 1))[:, :, :conv1.shape[2], :conv1.shape[3]]  #  1/4   64\n",
    "        conv1 = self.deconv1(F.concat([conv2, conv1], 1))[:, :, :conv0.shape[2], :conv0.shape[3]]  #  1/2   32\n",
    "        conv0 = self.deconv0(F.concat([conv1, conv0], 1))[:, :, :x.shape[2], :x.shape[3]]  #  1/1   3\n",
    "\n",
    "        return conv0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络\n",
    "\n",
    "接下来我们开始训练网络。在此之前，假定您想要把网络存储在下面位置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./workspace/model.mge.state\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用下面的代码训练您的网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss: Tensor([0.3767]), speed: 1.89it/sec, tot: 0.5298s, data: 0.2936s, data/tot: 0.5542\n",
      "100: loss: Tensor([0.0736]), speed: 3.07it/sec, tot: 0.3257s, data: 0.2507s, data/tot: 0.7698\n",
      "200: loss: Tensor([0.0468]), speed: 4.70it/sec, tot: 0.2126s, data: 0.1381s, data/tot: 0.6499\n",
      "300: loss: Tensor([0.0366]), speed: 3.39it/sec, tot: 0.2951s, data: 0.2243s, data/tot: 0.7602\n",
      "400: loss: Tensor([0.0323]), speed: 6.59it/sec, tot: 0.1518s, data: 0.0815s, data/tot: 0.5369\n",
      "500: loss: Tensor([0.0297]), speed: 8.87it/sec, tot: 0.1128s, data: 0.0421s, data/tot: 0.3730\n",
      "600: loss: Tensor([0.0276]), speed: 10.21it/sec, tot: 0.0980s, data: 0.0278s, data/tot: 0.2839\n",
      "700: loss: Tensor([0.0266]), speed: 13.66it/sec, tot: 0.0732s, data: 0.0039s, data/tot: 0.0531\n",
      "800: loss: Tensor([0.0267]), speed: 8.50it/sec, tot: 0.1177s, data: 0.0469s, data/tot: 0.3985\n",
      "900: loss: Tensor([0.0255]), speed: 13.56it/sec, tot: 0.0737s, data: 0.0036s, data/tot: 0.0495\n",
      "1000: loss: Tensor([0.0253]), speed: 8.66it/sec, tot: 0.1155s, data: 0.0453s, data/tot: 0.3923\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from functools import lru_cache\n",
    "from megengine.optimizer import Adam\n",
    "\n",
    "train_steps = 1000\n",
    "batch_size = 8\n",
    "input_h = 256\n",
    "input_w = 256\n",
    "\n",
    "net = SimpleUNet()\n",
    "optimizer = Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "random.seed(100)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def load_image(path):\n",
    "    return np.load(path, mmap_mode=\"r\")\n",
    "\n",
    "train_patches = sorted([os.path.join(TRAIN_DATA_STORAGE, f) for f in os.listdir(TRAIN_DATA_STORAGE)])\n",
    "\n",
    "def load_batch():\n",
    "    batch_train = []\n",
    "    batch_gt = []\n",
    "    for i in range(batch_size):\n",
    "        path = random.choice(train_patches)\n",
    "        img = load_image(path)\n",
    "        batch_train.append(img[0])\n",
    "        batch_gt.append(img[1])\n",
    "    return np.array(batch_train), np.array(batch_gt)\n",
    "\n",
    "@mge.jit.trace\n",
    "def train_iter(batch_train, batch_gt):\n",
    "    pred = net(batch_train)\n",
    "    loss = F.abs(batch_gt - pred).mean()\n",
    "    optimizer.backward(loss)\n",
    "    return loss, pred\n",
    "\n",
    "loss_acc = 0\n",
    "loss_acc0 = 0\n",
    "\n",
    "for it in range(train_steps + 1):\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = 2e-4 * (train_steps - it) / train_steps\n",
    "\n",
    "    begin = time.time()\n",
    "    (batch_train, batch_gt) = load_batch()\n",
    "    data_load_end = time.time()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss, pred = train_iter(batch_train, batch_gt)\n",
    "    optimizer.step()\n",
    "    loss_acc = loss_acc * 0.99 + loss\n",
    "    loss_acc0 = loss_acc0 * 0.99 + 1\n",
    "    end = time.time()\n",
    "    \n",
    "    total_time = end - begin\n",
    "    data_load_time = data_load_end - begin\n",
    "    if it % 100 == 0:\n",
    "        print(\n",
    "            \"{}: loss: {}, speed: {:.2f}it/sec, tot: {:.4f}s, data: {:.4f}s, data/tot: {:.4f}\"\n",
    "            .format(it, loss_acc / loss_acc0, 1 / total_time, total_time,\n",
    "                    data_load_time, data_load_time / total_time))\n",
    "\n",
    "# 存储模型\n",
    "state = {\n",
    "    'net': net.state_dict(),\n",
    "    'opt': optimizer.state_dict(),\n",
    "}\n",
    "with open(MODEL_PATH, 'wb') as fout:\n",
    "    mge.save(state, fout)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载网络并推理\n",
    "\n",
    "训练完成后，就可以加载网络并进行推理：\n",
    "\n",
    "首先，测试数据在下面："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PNG_PATH=\"./workspace/test_png/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./workspace/result/./workspace/test_png/test/90/0100.png\n",
      "./workspace/result/./workspace/test_png/test/90/0200.png\n",
      "./workspace/result/./workspace/test_png/test/90/0300.png\n",
      "./workspace/result/./workspace/test_png/test/90/0400.png\n",
      "./workspace/result/./workspace/test_png/test/91/0100.png\n",
      "./workspace/result/./workspace/test_png/test/91/0200.png\n",
      "./workspace/result/./workspace/test_png/test/91/0300.png\n",
      "./workspace/result/./workspace/test_png/test/91/0400.png\n",
      "./workspace/result/./workspace/test_png/test/92/0100.png\n",
      "./workspace/result/./workspace/test_png/test/92/0200.png\n",
      "./workspace/result/./workspace/test_png/test/92/0300.png\n",
      "./workspace/result/./workspace/test_png/test/92/0400.png\n",
      "./workspace/result/./workspace/test_png/test/93/0100.png\n",
      "./workspace/result/./workspace/test_png/test/93/0200.png\n",
      "./workspace/result/./workspace/test_png/test/93/0300.png\n",
      "./workspace/result/./workspace/test_png/test/93/0400.png\n",
      "./workspace/result/./workspace/test_png/test/93/0500.png\n",
      "./workspace/result/./workspace/test_png/test/93/0600.png\n",
      "./workspace/result/./workspace/test_png/test/93/0700.png\n",
      "./workspace/result/./workspace/test_png/test/93/0800.png\n",
      "./workspace/result/./workspace/test_png/test/93/0900.png\n",
      "./workspace/result/./workspace/test_png/test/94/0100.png\n",
      "./workspace/result/./workspace/test_png/test/94/0200.png\n",
      "./workspace/result/./workspace/test_png/test/94/0300.png\n",
      "./workspace/result/./workspace/test_png/test/94/0400.png\n",
      "./workspace/result/./workspace/test_png/test/95/0100.png\n",
      "./workspace/result/./workspace/test_png/test/95/0200.png\n",
      "./workspace/result/./workspace/test_png/test/95/0300.png\n",
      "./workspace/result/./workspace/test_png/test/96/0100.png\n",
      "./workspace/result/./workspace/test_png/test/96/0200.png\n",
      "./workspace/result/./workspace/test_png/test/96/0300.png\n",
      "./workspace/result/./workspace/test_png/test/96/0400.png\n",
      "./workspace/result/./workspace/test_png/test/97/0100.png\n",
      "./workspace/result/./workspace/test_png/test/97/0200.png\n",
      "./workspace/result/./workspace/test_png/test/97/0300.png\n",
      "./workspace/result/./workspace/test_png/test/98/0100.png\n",
      "./workspace/result/./workspace/test_png/test/98/0200.png\n",
      "./workspace/result/./workspace/test_png/test/98/0300.png\n",
      "./workspace/result/./workspace/test_png/test/98/0400.png\n",
      "./workspace/result/./workspace/test_png/test/99/0100.png\n",
      "./workspace/result/./workspace/test_png/test/99/0200.png\n",
      "./workspace/result/./workspace/test_png/test/99/0300.png\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import io\n",
    "import numpy as np\n",
    "net = SimpleUNet()\n",
    "\n",
    "with open(MODEL_PATH, 'rb') as f:\n",
    "    net.load_state_dict(mge.load(f)['net'])\n",
    "    \n",
    "@mge.jit.trace\n",
    "def inference(inp):\n",
    "    return net(inp)\n",
    "\t\n",
    "#test_pngs = sorted([os.path.join(TEST_PNG_PATH, f) for f in os.listdir(TEST_PNG_PATH)])\n",
    "\n",
    "for test_png_num in os.listdir(TEST_PNG_PATH):\n",
    "\ttest_png_num=os.path.join(TEST_PNG_PATH,test_png_num)\n",
    "\ttest_png_num=test_png_num+\"/\"\n",
    "\t#print(test_png_num)\n",
    "\tcount=0\n",
    "\tfor test_png in os.listdir(test_png_num):\n",
    "\t\tif not \"png\" in test_png:\n",
    "\t\t\tcontinue\n",
    "\t\t#print(test_png_num)\n",
    "\t\t#print(test_png)\n",
    "\t\tfilePath=os.path.join(test_png_num,test_png)\n",
    "\t\tfilePath=os.path.join(\"./workspace/result/\",filePath)\n",
    "\t\tdirpath=os.path.join(\"./workspace/result/\",test_png_num)\n",
    "\t\ttest_png_path=os.path.join(test_png_num,test_png)\n",
    "\t\t#test_png=Image.open(test_png_path)\n",
    "\t\t#cv2.imread的返回值为3维数组\n",
    "\t\timg = cv2.imread(test_png_path,1)\n",
    "\t\t#print(test_png_path)\n",
    "\t\t#img = np.asarray(img)\n",
    "\t\t#img = cv2.imdecode(img, 1)\n",
    "\t\timg = cv2.resize(img, (0, 0), fx=4, fy=4)\n",
    "\t\timg = (np.float32(img) / 256).transpose((2, 0, 1))[None, :, :, :]\n",
    "\t\timg_out = inference(img)\n",
    "\t\timg_out = (img_out.numpy() * 256).clip(0, 255)[0].transpose((1, 2, 0)).copy()\n",
    "\t\t#content_out = cv2.imencode('.png', img_out)[1]\n",
    "\t\t#将图片存储\n",
    "\t\t#img_res=cv2.imread(img)\n",
    "\t\tif not os.path.exists(dirpath):\n",
    "\t\t\tos.makedirs(dirpath)\n",
    "\t\tcv2.imwrite(filePath,img_out)\n",
    "\t\tcount+=1\n",
    "\t\tif count%100==0:\n",
    "\t\t\tprint(filePath)\n",
    "\t\t#display(Image(data=content_out, width=400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##打成tar包后，进行打分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "from brainpp.oss import OSSPath\n",
    "import tarfile\n",
    "import io\n",
    "\n",
    "#fin=tarfile.open(fileobj=OSSPath('s3://emc-share/work/topaz_release/gt.tar').open('rb'))\n",
    "#fin=tarfile.open(fileobj=open('./gt.tar','rb'))\n",
    "\n",
    "out_path='s3://fhq-dataproc/work/topaz/release/prediction_bicubic.tar'\n",
    "#out_path='s3://fhq-dataproc/work/topaz/release/prediction_unet.tar'\n",
    "fout_s3=OSSPath(out_path).open('rb')\n",
    "#fout_s3=open('./prediction_bicubic.tar','rb')\n",
    "fout=tarfile.open(fileobj=fout_s3)\n",
    "\n",
    "cnt=0\n",
    "rms=0\n",
    "while True:\n",
    "\ttinfo=fin.next()\n",
    "\tif tinfo is None:\n",
    "\t\tbreak\n",
    "\toldname=tinfo.name\n",
    "\tprint(tinfo.name,file=sys.stderr)\n",
    "\tif not tinfo.isfile():\n",
    "\t\tcontinue\n",
    "\tcontent=fin.extractfile(tinfo).read()\n",
    "\timg=cv2.imdecode(np.fromstring(content,dtype='uint8'),1)\n",
    "\n",
    "\twhile True:\n",
    "\t\ttinfo=fout.next()\n",
    "\t\tif tinfo is None:\n",
    "\t\t\tbreak\n",
    "\t\tif tinfo.isfile():\n",
    "\t\t\tbreak\n",
    "\t#print(tinfo.name)\n",
    "\tif tinfo is None:\n",
    "\t\tprint('0')\n",
    "\t\tprint('number of files mismatch',cnt)\n",
    "\t\tsys.exit(0)\n",
    "\tif tinfo.name != oldname.replace('gt','test'):\n",
    "\t\tprint('0')\n",
    "\t\tprint('filename mismatch')\n",
    "\t\tsys.exit(0)\n",
    "\tcontent=fout.extractfile(tinfo).read()\n",
    "\timg_out=cv2.imdecode(np.fromstring(content,dtype='uint8'),1)\n",
    "\tif img.shape!=img_out.shape or img.dtype!=img_out.dtype:\n",
    "\t\tprint('0')\n",
    "\t\tprint('image size mismatch',img.shape,img_out.shape)\n",
    "\t\tsys.exit(0)\n",
    "\t\n",
    "\t#if cnt==100:\n",
    "\t\t#import balls.supershow2 as s2\n",
    "\t\t#s2.submit('debug',{\n",
    "\t\t\t#'img':img,\n",
    "\t\t\t#'img_out':img_out,\n",
    "\t\t\t#'path':out_path\n",
    "\t\t#},topic='topaz_release',post_key=out_path)\n",
    "\t\n",
    "\tr=np.square(np.float32(img)-img_out).mean()\n",
    "\trms+=r\n",
    "\tcnt+=1\n",
    "\tpsnr=np.log10(256*256/max((rms/cnt),1e-10))*10\n",
    "\n",
    "\tprint(tinfo.name,img.shape,'rms',rms/cnt,'psnr',psnr,'r',r,file=sys.stderr)\n",
    "psnr=np.log10(256*256/max((rms/cnt),1e-10))*10\n",
    "print(psnr)\n",
    "print('looks good')\n",
    "\n",
    "#    unet: 28.03\n",
    "# bicubic: 28.61\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
